{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe12cefb-43c4-45d1-b0cf-1012da72473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e6c2d-801d-4041-9d13-92c2b3ff3e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets Library\n",
    "> We will prepare the data for the transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5362bf-f492-4601-88c8-3ab6fdb8357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Features, ClassLabel, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385b3e03-7db0-4411-8b5f-09a2c9d939e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/capecape/aws_demo/runs/10cyqhc0\" target=\"_blank\">silvery-pine-5</a></strong> to <a href=\"https://wandb.ai/capecape/aws_demo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/capecape/aws_demo/runs/10cyqhc0?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb35e1168b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"aws_demo\", job_type=\"get_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f503ac3-ff35-4283-83ac-9a3a584d9e2d",
   "metadata": {},
   "source": [
    "we can grab the preprocessed dataset direcly from wandb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d747fd-f840-4f18-89e1-b9eb7643b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path  = wandb.use_artifact(\"capecape/aws_demo/splitted_dataset:latest\").download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a5146d-9476-446a-9163-c2475cc126df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/splitted_dataset:v0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da5dcf9-5ab7-45a7-8e52-a007edcb3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = wandb.Artifact(\"splitted_dataset\", type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa52c7f5-86d4-4c51-a0d7-68d1a891de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"negative\", \"positive\"]\n",
    "stock_features = Features({'Text': Value('string'), \n",
    "                           'labels': ClassLabel(names=labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c23475e-c242-498d-af53-f8d9f92e6e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d8dfb5a2e7af0ec3\n",
      "Reusing dataset csv (/home/paperspace/.cache/huggingface/datasets/csv/default-d8dfb5a2e7af0ec3/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c335611f8e304b809786cdcda5c9bc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={\"train\": os.path.join(dataset_path,\"train.csv\"), \n",
    "                                          \"test\": os.path.join(dataset_path, \"test.csv\")}, \n",
    "                       delimiter=',', \n",
    "                       features=stock_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653380a-2e41-4886-afb4-3f66d7a01e13",
   "metadata": {},
   "source": [
    "we get a `DatasetDict` object containing our split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b254b448-d2dd-4fa2-8cf9-65b07303de24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'labels'],\n",
       "        num_rows: 5212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'labels'],\n",
       "        num_rows: 579\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fe0c3-05e5-449f-8eba-728a9a5fe255",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A Simple bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28158e0-dbbe-4080-b303-d8be4715dee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a3ce1b-028c-4ab7-89cc-e36388c4d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/paperspace/.cache/huggingface/datasets/csv/default-d8dfb5a2e7af0ec3/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-055f664b758555b4.arrow\n",
      "Loading cached processed dataset at /home/paperspace/.cache/huggingface/datasets/csv/default-d8dfb5a2e7af0ec3/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-946972fb275e0871.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b89df03-e7bc-46e3-a809-8d14f69937d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 579\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeddcaad-38f6-4067-a15f-8ee426a0bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_training_args = {\n",
    "    'per_device_train_batch_size': 32,\n",
    "    'per_device_eval_batch_size': 32,\n",
    "    'num_train_epochs': 1,\n",
    "    'learning_rate': 2e-5,\n",
    "    'evaluation_strategy': 'epoch',\n",
    "    'save_strategy': 'epoch',\n",
    "    'save_total_limit': 2,\n",
    "    'logging_strategy': 'steps',\n",
    "    'logging_first_step': True,\n",
    "    'logging_steps': 5,\n",
    "    'report_to': 'wandb',\n",
    "    'fp16':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f0162ba-f30d-4639-a4b2-5888aa8edd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_metric = load_metric(\"recall\")\n",
    "f1_metric = load_metric('f1')\n",
    "accuracy_metric = load_metric('accuracy')\n",
    "precision_metric = load_metric('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5646f1fa-3b8e-4f10-9250-dfb6ee8a1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.sdk.integration_utils.data_logging import ValidationDataLogger\n",
    "\n",
    "validation_inputs = tokenized_datasets['test'].remove_columns(['labels', 'attention_mask', 'input_ids', 'token_type_ids'])\n",
    "validation_targets = [tokenized_datasets['test'].features['labels'].int2str(x) for x in dataset['test']['labels']]\n",
    "\n",
    "validation_logger = ValidationDataLogger(inputs = validation_inputs[:],targets = validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b98c50b1-47bf-4a07-8544-8ead16eeea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"Get a bunch of metrics and log predictions to wandb\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='macro')['recall']\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions,references=labels)['accuracy']\n",
    "    precision = precision_metric.compute(predictions=predictions,references=labels,average='macro')['precision']\n",
    "    \n",
    "    # convert predictions from class (0, 1) to label (Negative, Positive)\n",
    "    prediction_labels = [tokenized_datasets['test'].features['labels'].int2str(x.item()) for x in predictions]\n",
    "    \n",
    "    # log predictions\n",
    "    validation_logger.log_predictions(prediction_labels)\n",
    "\n",
    "    return {\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df0bf015-89ca-4675-869a-eb7a68b9d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(model, output_dir, tokenizer, data_collator, training_args, train, test):\n",
    "    \"Prepare the hf Trainer\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        **training_args\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=test,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f5d60-3a38-4795-8d54-df7a9e646403",
   "metadata": {},
   "source": [
    "Let's log predictions at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8754f8fc-a0a2-4f91-8423-e6783ec3e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_args=default_training_args):\n",
    "    trainer = get_trainer(\n",
    "    output_dir=f'training_dir',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    training_args=train_args,\n",
    "    train=tokenized_datasets['train'],\n",
    "    test=tokenized_datasets[\"test\"])\n",
    "    \n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a09fae9-3140-4131-9ce9-2b3e4ab5be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Text.\n",
      "***** Running training *****\n",
      "  Num examples = 5212\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 163\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163' max='163' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [163/163 01:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.502601</td>\n",
       "      <td>0.733078</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>0.753022</td>\n",
       "      <td>0.738051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to training_dir/checkpoint-163\n",
      "Configuration saved in training_dir/checkpoint-163/config.json\n",
      "Model weights saved in training_dir/checkpoint-163/pytorch_model.bin\n",
      "tokenizer config file saved in training_dir/checkpoint-163/tokenizer_config.json\n",
      "Special tokens file saved in training_dir/checkpoint-163/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3a1b9d-3095-4987-bd43-ccea2cd0f760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21372... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▅▆▄▆▇▇▇▅▆▃▅▅▆▄▅▄▄▅▅▄▃▃▁▃▄▂▃▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75302</td></tr><tr><td>eval/f1</td><td>0.73525</td></tr><tr><td>eval/loss</td><td>0.5026</td></tr><tr><td>eval/precision</td><td>0.73805</td></tr><tr><td>eval/recall</td><td>0.73308</td></tr><tr><td>eval/runtime</td><td>3.3019</td></tr><tr><td>eval/samples_per_second</td><td>175.353</td></tr><tr><td>eval/steps_per_second</td><td>5.754</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>163</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4569</td></tr><tr><td>train/total_flos</td><td>1371334820536320.0</td></tr><tr><td>train/train_loss</td><td>0.56358</td></tr><tr><td>train/train_runtime</td><td>79.8732</td></tr><tr><td>train/train_samples_per_second</td><td>65.253</td></tr><tr><td>train/train_steps_per_second</td><td>2.041</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">silvery-pine-5</strong>: <a href=\"https://wandb.ai/capecape/aws_demo/runs/10cyqhc0\" target=\"_blank\">https://wandb.ai/capecape/aws_demo/runs/10cyqhc0</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220131_141731-10cyqhc0/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae87d3-da43-496c-901e-3373bd3f4ac0",
   "metadata": {},
   "source": [
    "## Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db8e3ed-94ef-4e95-bf12-11198e49b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df4a6d77-8834-4bb0-ba0f-ac50349c8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37696c9b-22a4-4997-a8dc-c794f2e4d494",
   "metadata": {},
   "source": [
    "For `bayes`ian Sweeps,\n",
    "you also need to tell us a bit about your `metric`.\n",
    "We need to know its `name`, so we can find it in the model outputs\n",
    "and we need to know whether your `goal` is to `minimize` it\n",
    "(e.g. if it's the squared error)\n",
    "or to `maximize` it\n",
    "(e.g. if it's the accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4ecd544-9f5c-43db-ab7e-ed3cbd275e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {\n",
    "    'name': 'eval/loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d37440-0590-4af7-8067-76236f994ff3",
   "metadata": {},
   "source": [
    "Once you've picked a `method` to try out new values of the hyperparameters,\n",
    "you need to define what those `parameters` are.\n",
    "\n",
    "Most of the time, this step is straightforward:\n",
    "you just give the `parameter` a name\n",
    "and specify a list of legal `values`\n",
    "of the parameter.\n",
    "\n",
    "For example, when we choose the `optimizer` for our network,\n",
    "there's only a finite number of options.\n",
    "Here we stick with the two most popular choices, `adam` and `sgd`.\n",
    "Even for hyperparameters that have potentially infinite options,\n",
    "it usually only makes sense to try out\n",
    "a few select `values`,\n",
    "as we do here with the hidden `layer_size` and `dropout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38c62919-958e-42c6-ae0e-6f4943056aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "      },\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms \n",
    "        'distribution': 'q_log_uniform',\n",
    "        'q': 1,\n",
    "        'min': math.log(4),\n",
    "        'max': math.log(32),\n",
    "      },\n",
    "    'epochs': {\n",
    "        \"values\": [4,6,8,10]\n",
    "    }\n",
    "}\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ccc2634-6d40-44f7-abab-aa0c3868439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: txa10kwk\n",
      "Sweep URL: https://wandb.ai/capecape/aws_demo/sweeps/txa10kwk\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"aws_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71908b79-2e04-4f1d-a77c-6bb1be661607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'name': 'eval/loss', 'goal': 'minimize'},\n",
       " 'parameters': {'learning_rate': {'distribution': 'uniform',\n",
       "   'min': 0,\n",
       "   'max': 0.1},\n",
       "  'batch_size': {'distribution': 'q_log_uniform',\n",
       "   'q': 1,\n",
       "   'min': 1.3862943611198906,\n",
       "   'max': 3.4657359027997265},\n",
       "  'epochs': {'values': [4, 6, 8, 10]}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8504487d-84d2-41d5-a7e1-ebb24ca6a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        default_training_args[\"learning_rate\"] = config.learning_rate\n",
    "        default_training_args['per_device_train_batch_size'] = config.batch_size\n",
    "        default_training_args['per_device_eval_batch_size'] = config.batch_size\n",
    "        default_training_args[\"num_train_epochs\"] = config.epochs\n",
    "        \n",
    "        train(default_training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f2c0991-5bc0-47d6-8e79-136cb3bc2c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jd81cg58 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06550276443957684\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/capecape/aws_demo/runs/jd81cg58\" target=\"_blank\">colorful-sweep-1</a></strong> to <a href=\"https://wandb.ai/capecape/aws_demo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/capecape/aws_demo/sweeps/txa10kwk\" target=\"_blank\">https://wandb.ai/capecape/aws_demo/sweeps/txa10kwk</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using amp half precision backend\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Text.\n",
      "***** Running training *****\n",
      "  Num examples = 5212\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 14\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 14\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2984\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='530' max='2984' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 530/2984 01:54 < 08:51, 4.62 it/s, Epoch 1.42/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.275344</td>\n",
       "      <td>0.379965</td>\n",
       "      <td>0.189983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 14\n",
      "Saving model checkpoint to training_dir/checkpoint-373\n",
      "Configuration saved in training_dir/checkpoint-373/config.json\n",
      "Model weights saved in training_dir/checkpoint-373/pytorch_model.bin\n",
      "tokenizer config file saved in training_dir/checkpoint-373/tokenizer_config.json\n",
      "Special tokens file saved in training_dir/checkpoint-373/special_tokens_map.json\n",
      "Deleting older checkpoint [training_dir/checkpoint-652] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train_sweep, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d65d79-c659-4b07-9193-0ffa750167e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
